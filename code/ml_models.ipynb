{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mysterious-cooperation",
   "metadata": {},
   "source": [
    "### Importing Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "historical-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, r2_score, explained_variance_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from shap import TreeExplainer, LinearExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-coast",
   "metadata": {},
   "source": [
    "### Setting Up Data, ML Models, Hyperparameters, Loss Functions and Evaluation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "documentary-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['baseline_smri', 'followup_smri',\n",
    "             'baseline_fmri', 'followup_fmri',\n",
    "             'baseline_covr', 'followup_covr',\n",
    "             'baseline_smri_covr', 'followup_smri_covr',\n",
    "             'baseline_fmri_covr', 'followup_fmri_covr',\n",
    "             'baseline_smri_fmri_covr', 'followup_smri_fmri_covr']\n",
    "\n",
    "model_names  = ['en', 'hg']\n",
    "model_list   = {'en': ElasticNet(max_iter=1e7),\n",
    "                'hg': HistGradientBoostingRegressor(max_iter=100, max_leaf_nodes=50, scoring='neg_mean_absolute_error')}\n",
    "\n",
    "model_grids  = {'en': {'l1_ratio': [.1, .3, .5, .7, .9, .95, .99, 1],\n",
    "                      'alpha': np.logspace(-3, 3, 7)},\n",
    "                'hg': {'max_depth': [10, 20, 30],\n",
    "                       'l2_regularization': [0, 0.25, 0.5, 0.75, 1],\n",
    "                       'learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01]}}\n",
    "\n",
    "cv = KFold(n_splits=10)\n",
    "scoring = {'mnae': 'neg_mean_absolute_error', 'mdae': 'neg_median_absolute_error', 'rsqe': 'r2', 'evar': 'explained_variance'}\n",
    "per_strategy_best_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-fifteen",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "facial-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(X, y, model_name):\n",
    "    model = model_list[model_name]\n",
    "    grid  = model_grids[model_name]\n",
    "    search = GridSearchCV(model, grid, scoring='neg_mean_squared_error', n_jobs=-1, cv=cv, refit=True, verbose=0)\n",
    "    search.fit(X,y)\n",
    "    best_estimator = search.best_estimator_\n",
    "    return best_estimator\n",
    "\n",
    "def find_shapely(model, X_train, y_train, X_test, model_name, filename):\n",
    "    if(model_name=='en'):\n",
    "        model = model.fit(X_train, y_train)\n",
    "        explainer = shap.LinearExplainer(model, X_train)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        \n",
    "        shap.summary_plot(shap_values, X_test, plot_type=\"dot\", max_display=10, show=False)\n",
    "        plt.title('Elastic Net - ' + filename)\n",
    "        plt.savefig('../results/'+model_name+'/'+filename+\"/shapely_fexp.png\", dpi=600)\n",
    "        plt.close()\n",
    "        \n",
    "        shap.summary_plot(shap_values, X_test, plot_type=\"bar\", max_display=10, show=False)\n",
    "        plt.title('Elastic Net - ' + filename)\n",
    "        plt.xlabel('mean(|SHAP value|)')\n",
    "        plt.savefig('../results/'+model_name+'/'+filename+\"/shapely_fimp.png\", dpi=600)\n",
    "        plt.close()\n",
    "    \n",
    "    elif(model_name=='hg'):\n",
    "        model = model.fit(X_train, y_train)\n",
    "        explainer = TreeExplainer(model, X_train)\n",
    "        shap_values = explainer.shap_values(X_test, check_additivity=False)\n",
    "        \n",
    "        shap.summary_plot(shap_values, X_test, plot_type=\"dot\", max_display=10, show=False)\n",
    "        plt.title('Histogram Gradient Boosted Trees - ' + filename)\n",
    "        plt.savefig('../results/'+model_name+'/'+filename+\"/shapely_fexp.png\", dpi=600)\n",
    "        plt.close()\n",
    "        \n",
    "        shap.summary_plot(shap_values, X_test, plot_type=\"bar\", max_display=10, show=False)\n",
    "        plt.title('Histogram Gradient Boosted Trees - ' + filename)\n",
    "        plt.xlabel('mean(|SHAP value|)')\n",
    "        plt.savefig('../results/'+model_name+'/'+filename+\"/shapely_fimp.png\", dpi=600)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-standing",
   "metadata": {},
   "source": [
    "### Core Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hollywood-pledge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [1:00:44<00:00, 303.68s/it]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- en ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [7:45:18<00:00, 2326.52s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- hg ---\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    performance = pd.DataFrame(columns=filenames)\n",
    "    best_model_ = {}\n",
    "    \n",
    "    for filename in tqdm(filenames):        \n",
    "        df_train = pd.read_pickle('../data/train/'+filename)\n",
    "        X_train = df_train.drop('cbcl_scr_dsm5_depress_t', axis=1)\n",
    "        y_train = df_train['cbcl_scr_dsm5_depress_t']\n",
    "        \n",
    "        df_test = pd.read_pickle('../data/test/'+filename)\n",
    "        X_test = df_test.drop('cbcl_scr_dsm5_depress_t', axis=1)\n",
    "        y_test = df_test['cbcl_scr_dsm5_depress_t']\n",
    "\n",
    "        best_model = execute(X_train, y_train, model_name) \n",
    "        best_model_[filename] = best_model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        performance.loc['held-out mean absolute error', filename]   = '%.3f'%mean_absolute_error(y_test, y_pred)\n",
    "        performance.loc['held-out median absolute error', filename] = '%.3f'%median_absolute_error(y_test, y_pred)\n",
    "        performance.loc['held-out r2 score', filename]              = '%.3E'%r2_score(y_test, y_pred)\n",
    "        performance.loc['held-out explained variance', filename]    = '%.3E'%explained_variance_score(y_test, y_pred)\n",
    "        \n",
    "        df = pd.concat([df_train, df_test])\n",
    "        X = df.drop('cbcl_scr_dsm5_depress_t', axis=1)\n",
    "        y = df['cbcl_scr_dsm5_depress_t']\n",
    "\n",
    "        results = cross_validate(best_model, X, y, cv=cv, scoring=scoring, return_train_score=True)\n",
    "        performance.loc['test mean absolute error', filename] =  '%.3f ± %.3f'%(-results['test_mnae'].mean(), results['test_mnae'].std())\n",
    "        performance.loc['test median absolute error', filename] =  '%.3f ± %.3f'%(-results['test_mdae'].mean(), results['test_mdae'].std())\n",
    "        performance.loc['test r2 score', filename] =  '%.3E ± %.3E'%(results['test_rsqe'].mean(), results['test_rsqe'].std())\n",
    "        performance.loc['test explained variance', filename] =  '%.3E ± %.3E'%(results['test_evar'].mean(), results['test_evar'].std())\n",
    "\n",
    "        performance.loc['train mean absolute error', filename] =  '%.3f ± %.3f'%(-results['train_mnae'].mean(), results['train_mnae'].std())\n",
    "        performance.loc['train median absolute error', filename] =  '%.3f ± %.3f'%(-results['train_mdae'].mean(), results['train_mdae'].std())\n",
    "        performance.loc['train r2 score', filename] =  '%.3E ± %.3E'%(results['train_rsqe'].mean(), results['train_rsqe'].std())\n",
    "        performance.loc['train explained variance', filename] =  '%.3E ± %.3E'%(results['train_evar'].mean(), results['train_evar'].std())\n",
    "\n",
    "        importances_mean = pd.DataFrame(columns=X.columns)\n",
    "        importances_std = pd.DataFrame(columns=X.columns)\n",
    "\n",
    "        find_shapely(best_model, X_train, y_train, X_test, model_name, filename)\n",
    "    \n",
    "    print('--- %s ---'%(model_name))\n",
    "    \n",
    "    performance.sort_index(ascending=True).to_excel('../results/'+model_name+'/performance.xlsx')\n",
    "    per_strategy_best_models[model_name] = best_model_\n",
    "    \n",
    "    \n",
    "pd.DataFrame(per_strategy_best_models).to_pickle('../results/per_strategy_best_models')\n",
    "pd.DataFrame(per_strategy_best_models).to_excel('../results/per_strategy_best_models.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-colors",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
